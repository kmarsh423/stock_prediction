{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times \n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a,b):\n",
    "    # shufflemtwo arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "    \n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                 test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe.\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for intance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 ( that is 50+10)\n",
    "    # this last sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"] = X[train_samples:]\n",
    "        result[\"y_test\"] = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:\n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                    test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets and convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features,units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers -1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units,return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 4\n",
    "# whether to scale feature columns and output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "#features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% droput\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "#SPY stock market\n",
    "ticker = \"SPY\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they do not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 24s 231ms/step - loss: 0.0040 - mean_absolute_error: 0.0490 - val_loss: 3.2243e-04 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00032, saving model to results\\2022-01-15_SPY-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-4-layers-2-units-256.h5\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 18s 201ms/step - loss: 5.1805e-04 - mean_absolute_error: 0.0209 - val_loss: 7.3298e-05 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00032 to 0.00007, saving model to results\\2022-01-15_SPY-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-4-layers-2-units-256.h5\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 18s 200ms/step - loss: 3.9173e-04 - mean_absolute_error: 0.0184 - val_loss: 8.0169e-05 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00007\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 18s 202ms/step - loss: 3.6033e-04 - mean_absolute_error: 0.0169 - val_loss: 6.8370e-05 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00007 to 0.00007, saving model to results\\2022-01-15_SPY-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-4-layers-2-units-256.h5\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 19s 206ms/step - loss: 3.0120e-04 - mean_absolute_error: 0.0153 - val_loss: 5.4960e-04 - val_mean_absolute_error: 0.0276\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00007\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 18s 202ms/step - loss: 3.7366e-04 - mean_absolute_error: 0.0177 - val_loss: 6.1740e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00007 to 0.00006, saving model to results\\2022-01-15_SPY-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-4-layers-2-units-256.h5\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 18s 203ms/step - loss: 3.0064e-04 - mean_absolute_error: 0.0153 - val_loss: 4.8716e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00006 to 0.00005, saving model to results\\2022-01-15_SPY-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-4-layers-2-units-256.h5\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 18s 203ms/step - loss: 2.5508e-04 - mean_absolute_error: 0.0136 - val_loss: 6.4317e-05 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00005\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 18s 200ms/step - loss: 2.8581e-04 - mean_absolute_error: 0.0150 - val_loss: 3.5480e-04 - val_mean_absolute_error: 0.0191\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00005\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 18s 203ms/step - loss: 3.0916e-04 - mean_absolute_error: 0.0159 - val_loss: 1.2382e-04 - val_mean_absolute_error: 0.0126\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00005\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE,\n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                     dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see\n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"], batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(data[\"X_test\"],data[\"y_test\"]), callbacks=[checkpointer, tensorboard], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 4 days is $466.83\n",
      "huber_loss loss: 4.8715792217990384e-05\n",
      "Mean Absolute Error: 28.258611209762716\n",
      "Accuracy score: 0.52864044168392\n",
      "Total buy profit: 867.5268478393555\n",
      "Total sell profit: -636.3774662017822\n",
      "Total profit: 231.14938163757324\n",
      "Profit per trade: 0.15952338277265235\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is ${future_price:.2f}\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
